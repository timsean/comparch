\documentclass[10pt]{article}

\usepackage{graphicx}
\usepackage{float}
\usepackage{svg}
\usepackage[T1]{fontenc}
\usepackage[titletoc]{appendix}
\usepackage[margin=0.7in]{geometry}
\usepackage{blindtext}
\usepackage[english]{babel}
\usepackage{multirow}
\usepackage{courier}
\usepackage{fancyhdr}
\usepackage{makecell}
\pagestyle{fancy}
\lhead{Tim Yao - ty252}

\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Verilog,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  keepspaces=true,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=false,
  breakatwhitespace=true,
  tabsize=2
}

\title{ECE 4750 PSET 2}
\author{Tim Yao (ty252)}
\date{Oct 10, 2015}

\begin{document}
\maketitle
\newcommand*{\tableindent}{\hspace*{0.3cm}}%

\section{PARCv1 Instruction Cache} 
\subsection{Categorizing Cache Misses}
\begin{figure}[H]
\centering
\begin{tabular}{clcc}
\hline
\textbf{Addr} &\textbf{Instruction}& \textbf{Iteration 1} & \textbf{Iteration 2}\\
\hline
& loop: & & \\
\hline
0x108 & \tableindent addiu r1, r1, -1 & compulsory & \\
\hline
0x10c & \tableindent addiu r2, r2, -1 & 		   & \\
\hline
0x110 & \tableindent j foo			  & compulsory & conflict \\
\hline
	  & ...							  & 		   & \\
\hline
	  & foo:						  & 		   & \\
\hline
0x218 & \tableindent addiu r6, r6, 1  & compulsory & conflict \\
\hline
0x21c & \tableindent bne r1, r0, loop & 	       & \\
\hline
\end{tabular}
\caption{Cache Miss Type}
\end{figure}

\subsection{Average Memory Access Latency}
Looking at iteration 2, we can see that there are 2 misses out of the 5 instructions. Therefore the miss rate for 64 iterations of the loop is 0.4.The average memory access latency is:AMAL = (Hit Time) + (Miss Rate $\times$ Miss Penalty)AMAL = 1 + (0.4 $\times$ 5)AMAL = 3 cyclesThe AMAL is dominated by conflict misses, as shown by the miss chart above. Compulsory misses only occur on the first iteration of the loop.

\subsection{Set-Associativity}
The cache performance will increase significantly, because there will no longer be conflict misses during the loop. With this new cache microarchitecture, only compulsory misses will be left. 

\cleardoublepage
\section{Page-Based Memory Translation}

\section{Two-Level Page Tables}
The 16-bit virtual address is used as the following:
\begin{figure}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
Bits 14-15 & Bits 12-13 & Bits 0-11 \\
\hline
XX & XX & XXXXXXXXXXXX \\
\hline
\multicolumn{2}{|c}{Virtual Page Number} & Page Offset \\
L1 Index & L2 Index & Page Offset \\
\hline
\end{tabular}
\caption{Virtual Address Usage}
\end{figure}
Page Tables:
\begin{figure}[H]
\centering
{
\begin{tabular}{@{\extracolsep{3pt}}lcc@{}}
\Xhline{2\arrayrulewidth}
& \multicolumn{2}{c}{\textbf{Page-Table Entry}}
\textbf{Paddr of PTE} & \textbf{Valid} & \textbf{Paddr}\\
\Xhline{2\arrayrulewidth}
0xffffc & 1 & 0xfffe0 \\
\hline
0xffff8 & &  \\
\hline
0xffff4 & &  \\
\hline
0xffff0 & 1 & 0xfffb0 \\
\Xhline{2\arrayrulewidth}
0xfffec & 1 & 0x05000 \\
\hline
0xfffe8 & 1 & 0x07000 \\
\hline
0xfffe4 & &  \\
\hline
0xfffe0 & & \\
\Xhline{2\arrayrulewidth}
0xfffdc & & \\
\hline
0xfffd8 & &  \\
\hline
0xfffd4 & &  \\
\hline
0xfffd0 & & \\
\Xhline{2\arrayrulewidth}
0xfffcc & & \\
\hline
0xfffc8 & &  \\
\hline
0xfffc4 & &  \\
\hline
0xfffc0 & & \\
\Xhline{2\arrayrulewidth}
0xfffbc & 1 & 0x01000\\
\hline
0xfffb8 & 1 & 0x04000\\
\hline
0xfffb4 & 1 & 0x00000 \\
\hline
0xfffb0 & & \\
\Xhline{2\arrayrulewidth}
\end{tabular}
}
\caption{Contents of Physical Memory with Page Tables}
\end{figure}

\subsection{Translation-Lookaside Buffer}
\begin{figure}[H]
\centering
{
\begin{tabular}{@{\extracolsep{3pt}}ccccccccc@{}}
\hline
& & & & \textbf{Total} & & & & \\
\textbf{Transaction} & & \textbf{Page} & & \textbf{Num Mem} & \multicolumn{2}{c}{\textbf{TLB Way 0}} & \multicolumn{2}{c}{\textbf{TLB Way 1}} \\
\cline{6-7}
\cline{8-9}
\textbf{Address} & \textbf{VPN} & \textbf{Offset} & \textbf{m/h} & \textbf{Accesses} & \textbf{VPN} & \textbf{PPN} & \textbf{VPN} & \textbf{PPN} \\
\hline
0xeff4 & 0xe & 0xff4 & m & 3 & - & - & - & - \\
\hline
0x2ff0 & 0x2 & 0xff0 & m & 3 & 0xe & 0x07 & & \\
\hline
0xeff8 & 0xe & 0xff8 & h & 1 &  &  & 0x2 & 0x04 \\
\hline
0x2ff4 & 0x2 & 0xff4 & h & 1 & & & & \\
\hline
0xeffc & 0xe & 0xffc & h & 1 & & & & \\
\hline
0x2ff8 & 0x2 & 0xff8 & h & 1 & & & & \\
\hline
0xf000 & 0xf & 0x000 & m & 3 & & & & \\
\hline
0x2ffc & 0x2 & 0xffc & h & 1 & 0xf & 0x05 & & \\
\hline
0xf004 & 0xf & 0x004 & h & 1 & & & & \\
\hline
0x3000 & 0x3 & 0x000 & m & 3 & & & & \\
\hline
0xf008 & 0xf & 0x008 & h & 1 & & & 0x3 & 0x01 \\
\hline
0x3004 & 0x3 & 0x004 & h & 1 & & & 0x2 & 0x04 \\
\hline
0xf00c & 0xf & 0x00c & h & 1 & & & & \\
\hline
0x3008 & 0x3 & 0x008 & h & 1 & & & & \\
\hline
\end{tabular}
}
\caption{TLB Contents Over Time}
\end{figure}

\cleardoublepage
\section{Multiplier Microarchitecture}
\begin{figure}[H]
\centering
{\setlength{\tabcolsep}{2pt}
\begin{tabular}{@{\extracolsep{3pt}}clccccccc@{}}
\hline
& & \textbf{Num} & \textbf{Cycle} & \multicolumn{2}{c}{\textbf{Transaction}} & \multicolumn{2}{c}{\textbf{Transaction}} & \textbf{Total} \\
& & \textbf{Trans} &  \textbf{Time} & \multicolumn{2}{c}{\textbf{Latency}} & \multicolumn{2}{c}{\textbf{Throughput}} & \textbf{Execution Time} \\
\cline{3-3} 
\cline{4-4}
\cline{5-6}
\cline{7-8}
\cline{9-9}
& \textbf{Microarchitecture} & (\#) & ($\tau$) & (cyc) & ($\tau$) & (trans/cyc) & (cyc/trans) & ($\tau$) \\
\hline
(a) & 1-Cycle & 60 & 62 & 1 & 62 & 1 & 1 & 3720\\
\hline
(b) & Iterative & 60 & 20 & 4 & 60 & 0.25 & 4 & 3600\\
\hline
(c) & 2-Cycle Unpiplined & 60 & 32 & 2 & 64 & 0.5 & 2 & 3840\\
\hline
(c) & 2-Cycle Pipelined & 60 & 32 & 2 & 64 & 0.98 & 1.02 & 1952\\
\hline
(d) & 4-Cycle Unpiplined & 60 & 17 & 4 & 68 & 0.25 & 4 & 4080\\
\hline
(d) & 4-Cycle Piplined & 60 & 17 & 4 & 68 & 0.95 & 1.05 & 1071\\
\hline
(e) & Var-Lat Pipelined & 60 & 20 & 1-5 & 20-100 & 0.59 & 1.7 & 2040\\
\hline
\end{tabular}
}
\caption{Evaluation of Various Multiplier Microarchitectures}
\label{fig:mult_arch}
\end{figure}

\subsection{Iterative Microarchitecture}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
& & \multicolumn{16}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16\\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & Z & Z & Z & Z & & & & & & & & & & & &\\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & & & & Z & Z & Z & Z & & & & & & & &\\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & & & & & & & Z & Z & Z & Z & & & &\\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & & & & & & & & & & Z & Z & Z & Z\\
\hline
\end{tabular}
\caption{Iterative Multiplier Transaction vs Time Diagram}
\label{fig:iter_trans_diagram}
\end{figure}

\subsection{Two-Cycle Microarchitecture}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c|c|c|c}
\hline
& & \multicolumn{8}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8\\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & X0 & X1 & & & & & &\\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & & X0 & X1 & & & &\\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & & & X0 & X1 & &\\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & & & & X0 & X1\\
\hline
\end{tabular}
\caption{2 Cycle Unpipelined Transaction vs Time Diagram}
\label{fig:2cycunpipe_trans_diagram}
\end{figure}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c}
\hline
& & \multicolumn{5}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5  \\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & X0 & X1 & & & \\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & X0 & X1 & & \\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & X0 & X1 & \\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & X0 & X1 \\
\hline
\end{tabular}
\caption{2 Cycle Pipelined Transaction vs Time Diagram}
\label{fig:2cycpipe_trans_diagram}
\end{figure}

\subsection{Two-Cycle Microarchitecture}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
& & \multicolumn{16}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16\\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & X0 & X1 & X2 & X3 & & & & & & & & & & & &\\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & & & & X0 & X1 & X2 & X3 & & & & & & & &\\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & & & & & & & X0 & X1 & X2 & X3 & & & &\\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & & & & & & & & & & X0 & X1 & X2 & X3\\
\hline
\end{tabular}
\caption{4 Cycle Unpipelined Transaction vs Time Diagram}
\label{fig:4cycunpipe_trans_diagram}
\end{figure}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c|c|c}
\hline
& & \multicolumn{5}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & X0 & X1 & X2 & X3 & & & \\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & X0 & X1 & X2 & X3 & & \\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & X0 & X1 & X2 & X3 & \\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & X0 & X1 & X2 & X3 \\
\hline
\end{tabular}
\caption{4 Cycle Pipelined Transaction vs Time Diagram}
\label{fig:4cycpipe_trans_diagram}
\end{figure}

\subsection{Variable-Latency Microarchitecture}
\begin{figure}[H]
\centering
\begin{tabular}{cl|c|c|c|c|c|c|c|c|c|c}
\hline
& & \multicolumn{10}{c}{Cycle} \\
& \textbf{Transaction} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline
1 & \texttt{mul 0xdeadbeef, 0xf} & Y & X0 & X1 & X2 & X3 & & & & & \\
\hline
2 & \texttt{mul 0xf5fe4fbc, 0x7} & & Y & Y & X1 & X2 & X3 & & & & \\
\hline
3 & \texttt{mul 0x0a01b044, 0x3} & & & & Y & Y & X2 & X3 & & & \\
\hline
4 & \texttt{mul 0xdeadbeef, 0xf} & & & & & & Y & X0 & X1 & X2 & X3 \\
\hline
\end{tabular}
\caption{Variable-Latency Microarchitecture Transaction vs Time Diagram}
\label{fig:varlat_trans_diagram}
\end{figure}

\subsection{Comparison of Microarchitectures}
The 4 cycle pipelined architecture has the highest performance. It provided the best transaction throughput and therefore lowest total execution time. The 4 cycle pipelined multiplier allowed us to execute 4 multiply instructions at the same time provided that there are no data dependencies between them. For this specific type of mlutiplier (32 bit operand by 4 bit operand), anything more than a 4 cycle pipeline will not provide any benefits. The best performance is achieved when the number of cycles in the pipeline is equal to the number of bits in the second operand (ie. a 32 bit by 16 bit multiplier will have a 16-cycle pipeline). The variable latency pipelined multiplier can provide the same transaction throughput as the 4-cycle pipeline and better transaction latency, but only for certain data sets and instruction ordering (ie. a continuous stream of data that only needs the lowest 2 bits). Due to the necessity to stall in the Y stage, the variable latency multiplier resulted in a worse throughput and latency when compared to the 4-cycle pipeline in our tests. With a larger second operand (of n bits) and a more random data set, the variable latency multiplier will have roughly the same transaction throughput as the n-cycle pipeline, but a slightly better transaction latency.

In terms of area, the fixed latency multiplier will have the smallest area while the variable latency pipelined multiplier will have the largest area. The 4-cycle pipelined multiplier, with the second largest area, provided the best performance in this test due to the uniqueness of this data set. I believe that the area difference between these different architectures is not significant because they only involve the addition of registers and muxes, while the amount of combinational logic for arithmetic purposes remained roughly the same (same number of 32-bit adders and shifters). 

While the 4 cycle pipelined multiplier provided the best throughput, it also had one of the worst latency. Therefore, if there are data dependencies between a succession of transactions, a fixed latency or variable latency pipelined multiplier will have provided better performance due to their lower transaction latency. In the case of the variable latency multiplier, the performance will vary depending on the data set as stated before. 

Overall, for a 32-bit by 4-bit multiplier, the 4 cycle pipelined multiplier will provide the best performance in general. With good software scheduling, we can minimize the penalty for data dependencies and therefore maintain a max throughput. However, if we wish to implement a larger multiplier such as a 32-bit by 16-bit multiplier, we should choose the variable-latency pipelined multiplier instead. With the larger operand, there are more upper bits that we can potentially skip, therefore the performance benefits of skipping them are also greater, especially when there are data dependencies. In that case, it is likely to outperform a 16-cycle pipelined multiplier.

\cleardoublepage
\section{Two-Cycle Pipelined Integer ALU and Multiplier}
\subsection{Part 4.A Control and Data Hazard Latencies}
Jump Resolution Latency = 2\\
Branch Resolution Latency = 4\\
ALU-use Delay Latency = 2\\
Load-use Delay Latency = 3\\

\subsection{Resolving Data Hazards with Software Scheduling}
\begin{lstlisting}
        bne r1, r0, done
        lw r5, 0(r2)
        lw r6, 0(r3)
        addiu r8, r4, 4
        nop
        addu r7, r5, r6
        nop
        sw r7, 0(r8)
        ...
done:   addiu r10, r9, 1
\end{lstlisting}
By swapping the addu and addiu instructions, we can avoid 1 nop for the dependence between the addu and the lw instructions. Regardless of how the addiu and addu instructions are scheduled, there will always be a nop right before the sw instruction due to the dependence.
\begin{figure}[H]
\centering
\begin{tabular}{cll|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
& \multicolumn{2}{l}{\textbf{Dynamic}} & \multicolumn{13}{c}{Cycle} \\
& \multicolumn{2}{l}{\textbf{Transaction}} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 \\
\hline
1 & \texttt{bne} & \texttt{r1, r0, done} & F & D & X0 & X1 & M & W & & & & & & &\\
\hline
2 & \texttt{lw} & \texttt{r5, 0(r2)} & & F & D & X0 & X1 & M & W & & & & & &\\
\hline
3 & \texttt{lw} & \texttt{r6, 0(r3)} & & & F & D & X0 & X1 & M & W & & & & &\\
\hline
4 & \texttt{addiu} & \texttt{r8, r4, 4} & & & & F & D & X0 & X1 & M & W & & & &\\
\hline
5 & \texttt{nop} & & & & & & F & D & X0 & X1 & M & W & & &\\
\hline
6 & \texttt{addu} & \texttt{r7, r5, r6} & & & & & & F & D & X0 & X1 & M & W & &\\
\hline
7 & \texttt{nop} & & & & & & & & F & D & X0 & X1 & M & W &\\
\hline
8 & \texttt{sw} & \texttt{r7, 0(r8)} & & & & & & & & F & D & X0 & X1 & M & W \\
\hline
\end{tabular}
\caption{Software Scheduling Pipeline}
\label{fig:sixstage_softwaresch_pipe_diagram}
\end{figure}
Instruction 6 (addu)'s D stage depends on instruction 2 (lw)'s M stage and instruction 3 (lw)'s M stage.\\
Instruction 7 (sw)'s D stage depends on instruction 4 (addiu)'s X1 stage and instruction 6 (addu)'s X1 stage.\\

\subsection{Resolving Data Hazards with Stalling}
\begin{figure}[H]
\centering
\begin{tabular}{cll|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
& \multicolumn{2}{l}{\textbf{Dynamic}} & \multicolumn{14}{c}{Cycle} \\
& \multicolumn{2}{l}{\textbf{Transaction}} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14\\
\hline
1 & \texttt{bne} & \texttt{r1, r0, done} & F & D & X0 & X1 & M & W & & & & & & & &\\
\hline
2 & \texttt{lw} & \texttt{r5, 0(r2)} & & F & D & X0 & X1 & M & W & & & & & & &\\
\hline
3 & \texttt{lw} & \texttt{r6, 0(r3)} & & & F & D & X0 & X1 & M & W & & & & & &\\
\hline
4 & \texttt{addu} & \texttt{r7, r5, r6} & & & & F & D & D & D & X0 & X1 & M & W & & &\\
\hline
5 & \texttt{addiu} & \texttt{r8, r4, 4} & & & & & F & F & F & D & X0 & X1 & M & W & &\\
\hline
6 & \texttt{sw} & \texttt{r7, 0(r8)} & & & & & & & & F & F & D & X0 & X1 & M & W \\
\hline
\end{tabular}
\caption{Hardware Stalling Pipeline}
\label{fig:sixstage_hardwarestall_pipe_diagram}
\end{figure}
Instruction 6 (addu)'s D stage depends on instruction 2 (lw)'s M stage and instruction 3 (lw)'s M stage.\\
Instruction 7 (sw)'s D stage depends on instruction 4 (addiu)'s X1 stage and instruction 6 (addu)'s X1 stage.\\

\subsection{New Stall Signal}
\begin{lstlisting}
ostall_load_use_X_rs_D
  =    val_D && rs_en_D && (val_X0 || val_X1) && (rf_wen_X0 || rf_wen_X1)
    && ((inst_rs_D == rf_waddr_X0) || (inst_rs_D == rf_waddr_X1)) 
    && ((rf_waddr_X0 != 0) || (rf_waddr_X1 != 0))
    && ((op_X0 == LW) || (op_X1 == LW))
ostall_load_use_X_rt_D
  =    val_D && rt_en_D && (val_X0 || val_X1) && (rf_wen_X0 || rf_wen_X1)
    && ((inst_rt_D == rf_waddr_X0) || (inst_rt_D == rf_waddr_X1)) 
    && ((rf_waddr_X0 != 0) || (rf_waddr_X1 != 0))
    && ((op_X0 == LW) || (op_X1 == LW))
ostall_alu_use_X_rs_D
  =    val_D && rs_en_D && val_X0 && rf_wen_X0
    && (inst_rs_D == rf_waddr_X0) 
    && (rf_waddr_X0 != 0)
ostall_alu_use_X_rt_D
  =    val_D && rt_en_D && val_X0 && rf_wen_X0
    && (inst_rt_D == rf_waddr_X0) 
    && (rf_waddr_X0 != 0)
stall_D
  =    val_D && !squash_D
    && ((ostall_load_use_X_rs_D || ostall_load_use_X_rt_D) || 
       (ostall_alu_use_X_rs_D || ostall_alu_use_X_rt_D))
\end{lstlisting}

\subsection{Resolving Control Hazards with Scheduling and Speculation}
\begin{figure}[H]
\centering
\begin{tabular}{cll|c|c|c|c|c|c|c|c|c|c}
\hline
& \multicolumn{2}{l}{\textbf{Dynamic}} & \multicolumn{10}{c}{Cycle} \\
& \multicolumn{2}{l}{\textbf{Transaction}} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
\hline
1 & \texttt{bne} & \texttt{r1, r0, done} & F & D & X0 & X1 & M & W & & & & \\
\hline
2 & \texttt{lw} & \texttt{r5, 0(r2)} & & F & D & X0 & - & - & - & & & \\
\hline
3 & \texttt{lw} & \texttt{r6, 0(r3)} & & & F & D & - & - & - & - & & \\
\hline
4 & \texttt{addu} & \texttt{r7, r5, r6} & & & & F & - & - & - & - & - & \\
\hline
5 & \texttt{addiu} & \texttt{r10, r9, 1} & & & & & F & D & X0 & X1 & M & W \\
\hline
\end{tabular}
\caption{Squashing Pipeline}
\label{fig:squashing_diagram}
\end{figure}
\begin{figure}[H]
\centering
\begin{tabular}{cll|c|c|c|c|c|c|c|c|c|c}
\hline
& \multicolumn{2}{l}{\textbf{Dynamic}} & \multicolumn{10}{c}{Cycle} \\
& \multicolumn{2}{l}{\textbf{Transaction}} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
\hline
1 & \texttt{bne} & \texttt{r1, r0, done} & F & D & X0 & X1 & M & W & & & & \\
\hline
2 & \texttt{lw} & \texttt{r5, 0(r2)} & & F & D & X0 & X1 & M & W & & & \\
\hline
3 & \texttt{lw} & \texttt{r6, 0(r3)} & & & F & D & - & - & - & - & & \\
\hline
4 & \texttt{addu} & \texttt{r7, r5, r6} & & & & F & - & - & - & - & - & \\
\hline
5 & \texttt{addiu} & \texttt{r10, r9, 1} & & & & & F & D & X0 & X1 & M & W \\
\hline
\end{tabular}
\caption{Branch Delay Slot Pipeline}
\label{fig:branch_delay_diagram}
\end{figure}

\end{document}